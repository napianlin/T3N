{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,uid,tid,time_stamp,label):\n",
    "        self.children = {}\n",
    "        self.childrenList = []\n",
    "        self.num_children = 0\n",
    "        self.tid = tid\n",
    "        self.uid = uid\n",
    "        self.label = label\n",
    "        self.time_stamp = time_stamp\n",
    "    \n",
    "    def add_child(self,node):\n",
    "        if node.uid not in self.children:\n",
    "            self.children[node.uid] = node\n",
    "            self.num_children += 1\n",
    "        else:\n",
    "            self.children[node.uid] = node\n",
    "        self.childrenList = list(self.children.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,root):\n",
    "        self.root = root\n",
    "        self.tweet_id = root.tid\n",
    "        self.uid = root.uid\n",
    "        self.height = 0\n",
    "        self.nodes = 0\n",
    "    \n",
    "    def show(self):\n",
    "        queue = [self.root,0]\n",
    "        \n",
    "        while len(queue) != 0:\n",
    "            toprint = queue.pop(0)\n",
    "            if toprint == 0:\n",
    "                print('\\n')\n",
    "            else:\n",
    "                print(toprint.uid,end=' ')\n",
    "                queue += toprint.children.values()\n",
    "                queue.append(0)\n",
    "                \n",
    "    def insertnode(self,curnode,parent,child):\n",
    "        if curnode.uid == parent.uid:\n",
    "            curnode.add_child(child)\n",
    "            return 1\n",
    "\n",
    "        elif parent.uid in curnode.children:\n",
    "            s = self.insertnode(curnode.children[parent.uid],parent,child)\n",
    "            return 2\n",
    "        else:\n",
    "            for node in curnode.children:\n",
    "                s = self.insertnode(curnode.children[node],parent,child)\n",
    "                if s == 2:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPklFileNum(datapath,incSize,fileNum):\n",
    "    \n",
    "    with open(datapath+str(incSize)+'inc_'+str(fileNum)+'.pickle', 'rb') as handle:\n",
    "        twitTrees = pkl.load(handle)\n",
    "    return twitTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTreeFilesOfIncrement(datapath,incSize):\n",
    "    twittertrees = {}\n",
    "    \n",
    "    files = [x for x in os.listdir(t15Datapath) if str(incSize)+'inc' in x]\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        with open(datapath+file,'rb') as handle:\n",
    "            partialTrees = pkl.load(handle)\n",
    "        twittertrees.update(partialTrees)\n",
    "        \n",
    "    return twittertrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'twitter15'\n",
    "\n",
    "if dataset == 'twitter15':\n",
    "    %run ../twitter15/twitter15_text_processing.ipynb\n",
    "    t15Datapath = '../twitter15/pickledTrees/'\n",
    "    twitter15_trees = loadTreeFilesOfIncrement(t15Datapath,20)\n",
    "    %run ../twitter15/userdata_parser.ipynb\n",
    "    \n",
    "if dataset == 'twitter16':\n",
    "    %run ../twitter16/twitter16_text_processing.ipynb\n",
    "    t15Datapath = '../twitter16/pickledTrees/'\n",
    "    twitter15_trees = loadTreeFilesOfIncrement(t15Datapath,20)\n",
    "    %run ../twitter16/userdata_parser.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(userVects):\n",
    "    userVects[key] = userVects[key].float()\n",
    "\n",
    "userVects = defaultdict(lambda:torch.tensor([1.1100e+02, 1.5000e+01, 0.0000e+00, 7.9700e+02, 4.7300e+02, 0.0000e+00,\n",
    "        8.3326e+04, 1.0000e+00]),userVects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./textEncoders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./temporal_tree_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:2'\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labelMap = {}\n",
    "labelCount = 0\n",
    "for label in list(twitter15_labels.values()):\n",
    "    if label not in labelMap:\n",
    "        labelMap[label] = labelCount\n",
    "        labelCount += 1\n",
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "X = []\n",
    "y = []\n",
    "X_text = []\n",
    "\n",
    "for tid in twitter15_trees:\n",
    "        if tid in twitter15_trees and tid in twitter15_labels:\n",
    "            X.append(tuple((twitter15_trees[tid],twitter15_text[tid])))\n",
    "            y.append(labelMap[twitter15_labels[tid]])\n",
    "            X_text.append(twitter15_text[tid])\n",
    "            \n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda m, n: [(i*n//m + n//(2*m)) for i in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jointModel(nn.Module):\n",
    "    def __init__(self, treeEncoderType, textEncoderType, pretrainFiles, textparams, treeparams, X, y, device):\n",
    "        super(jointModel, self).__init__()\n",
    "        if textEncoderType == 'rnn':\n",
    "            self.textEncoderModel = TextEncoder(textEncoderType,textparams,X,y,device)\n",
    "            textparams['hidden_dim'] = textparams['hidden_dim']*self.textEncoderModel.textEncoder.numDirs\n",
    "            \n",
    "        if textEncoderType == 'bert':\n",
    "            self.textEncoderModel = BertTextEncoder(textEncoderType,{},X,y,device)\n",
    "            textparams['hidden_dim'] = 768\n",
    "        \n",
    "        if textEncoderType == 'attn':\n",
    "            self.textEncoderModel = AttentionTextEncoder(textEncoderType,textparams,X,y,device)\n",
    "            textparams['hidden_dim'] = textparams['hidden_dim']*self.textEncoderModel.textEncoder.numDirs*self.textEncoderModel.seq_dim\n",
    "            \n",
    "        if treeEncoderType == 'standard':\n",
    "            self.treeEncoderModel = treeEncoder(treeparams['cuda'],treeparams['in_dim'],treeparams['mem_dim'],treeparams['userVects'],treeparams['labels'],treeparams['labelMap'],treeparams['criterion'],device)\n",
    "        if treeEncoderType == 'decay':\n",
    "            self.treeEncoderModel = decayTreeEncoder(treeparams['cuda'],treeparams['in_dim'],treeparams['mem_dim'],treeparams['userVects'],treeparams['labels'],treeparams['labelMap'],treeparams['criterion'],device)\n",
    "        \n",
    "        if treeEncoderType == 'temporal':\n",
    "            self.treeEncoderModel = lstmTreeEncoder(treeparams['cuda'],treeparams['in_dim'],treeparams['mem_dim'],treeparams['userVects'],treeparams['labels'],treeparams['labelMap'],treeparams['criterion'],device)\n",
    "        \n",
    "        if pretrainFiles:\n",
    "            textcheckpoint = torch.load(pretrainFiles['text'])\n",
    "            self.textEncoderModel.textEncoder.load_state_dict(textcheckpoint['state_dict'])\n",
    "            \n",
    "            treecheckpoint = torch.load(pretrainFiles['tree'])\n",
    "            self.treeEncoderModel.load_state_dict(treecheckpoint['state_dict'])\n",
    "        \n",
    "        mem_dim = treeparams['mem_dim'] + textparams['hidden_dim']\n",
    "        \n",
    "        self.fc = nn.Linear(mem_dim,4)    \n",
    "            \n",
    "    def forward(self,tree,text):\n",
    "        treeVec = self.treeEncoderModel(tree)\n",
    "        treeVec = treeVec.reshape(-1)\n",
    "        \n",
    "        self.textEncoderModel.textEncoder = self.textEncoderModel.textEncoder.to('cpu')\n",
    "        textVec = self.textEncoderModel(text)\n",
    "        textVec = textVec.reshape(-1)\n",
    "#         print(treeVec.shape)\n",
    "#         print(textVec.shape)\n",
    "        combVec =  torch.cat((treeVec,textVec))\n",
    "#         combVec = textVec\n",
    "        out = self.fc(combVec)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,modelname):\n",
    "    optimizer = torch.optim.Adagrad(model.treeEncoderModel.parameters(),0.01)\n",
    "    \n",
    "    bertoptimizer = AdamW(model.textEncoderModel.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "    \n",
    "#     optimizer = torch.optim.Adagrad(model.parameters(),0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    maxAcc = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(5):\n",
    "        for treeSet, text in tqdm(x_train):\n",
    "            tree = treeSet[-1]\n",
    "            count += 1\n",
    "            idxs = f(5,len(treeSet))\n",
    "            trees = [ treeSet[idx] for idx in idxs ]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            bertoptimizer.zero_grad()\n",
    "            \n",
    "            pred = model(trees,text)\n",
    "            \n",
    "            label = Variable(torch.tensor(labelMap[treeSet[0].root.label]).reshape(-1).to(device))\n",
    "            loss = criterion(pred.reshape(1,4),label)\n",
    "#             print(loss)\n",
    "    \n",
    "#                 print('opt')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            bertoptimizer.step()\n",
    "        \n",
    "        print('train loss: ',loss.item())   \n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        allLabels = []\n",
    "        allPreds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for valSet, text in tqdm(x_test):\n",
    "                idxs = f(5,len(valSet))\n",
    "                trees = [ valSet[idx] for idx in idxs ]\n",
    "\n",
    "                predicted = model(trees,text)\n",
    "                preds.append(predicted)\n",
    "        #         print(predicted)\n",
    "                predicted =  torch.softmax(predicted,0)\n",
    "                predicted = torch.max(predicted, 0)[1].cpu().numpy().tolist()\n",
    "\n",
    "                labels.append(labelMap[trees[0].root.label])\n",
    "\n",
    "                allLabels.append(labelMap[trees[0].root.label])\n",
    "                allPreds.append(predicted)\n",
    "\n",
    "            predTensor = torch.stack(preds)\n",
    "            labelTensor = torch.tensor(labels).to(device)\n",
    "\n",
    "            print(allLabels,allPreds)\n",
    "\n",
    "            loss = criterion(predTensor.reshape(-1,4), labelTensor.reshape(-1))\n",
    "\n",
    "        cr = classification_report(allLabels,allPreds,output_dict=True)\n",
    "        cr['loss'] = loss.item()\n",
    "        cr['Acc'] = accuracy_score(allLabels,allPreds,)\n",
    "\n",
    "        if cr['Acc'] > maxAcc:\n",
    "            maxAcc = cr['Acc']\n",
    "            torch.save({'state_dict': model.state_dict()}, './jointlyTrainedResults/'+modelname+'.pth')\n",
    "\n",
    "\n",
    "        print('val loss: ',cr['loss'])\n",
    "        print(cr['Acc'])\n",
    "\n",
    "        with open('./jointlyTrainedResults/'+modelname+'json', 'a') as fp:\n",
    "            json.dump(cr, fp)\n",
    "            fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "treeparams = {\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'in_dim':8,\n",
    "    'mem_dim':100,\n",
    "    'userVects':userVects,\n",
    "    'labels':twitter15_labels,\n",
    "    'labelMap':labelMap,\n",
    "    'criterion':nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "textparams = {\n",
    "    'embedding_dim':256,\n",
    "    'hidden_dim': 50,\n",
    "    'output_dim':4,\n",
    "    'num_layers':1,\n",
    "    'bidir':True,\n",
    "    'rnnType':'gru'\n",
    "}\n",
    "\n",
    "treeTypes = ['standard','decay']\n",
    "textTypes = ['bert']\n",
    "pretrainTypes = [True,False]\n",
    "\n",
    "treeTypes = ['standard','decay']\n",
    "textTypes = ['bert']\n",
    "pretrainTypes = [True]\n",
    "\n",
    "for textType in textTypes:\n",
    "    for treeType in treeTypes:\n",
    "        for pretrainType in pretrainTypes:\n",
    "            model = jointModel(treeType,textType,pretrainType,textparams,treeparams,X_text,y,device)\n",
    "            model = model.to(device)\n",
    "            modelname = textType+'_'+treeType+'-tree_pretrain-'+str(pretrainType)\n",
    "            print(modelname)\n",
    "            trainModel(model,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeparams = {\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'in_dim':8,\n",
    "    'mem_dim':100,\n",
    "    'userVects':userVects,\n",
    "    'labels':twitter15_labels,\n",
    "    'labelMap':labelMap,\n",
    "    'criterion':nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "textparams = {\n",
    "    'embedding_dim':256,\n",
    "    'hidden_dim': 50,\n",
    "    'output_dim':4,\n",
    "    'num_layers':1,\n",
    "    'bidir':False,\n",
    "    'rnnType':'gru'\n",
    "}\n",
    "\n",
    "model = jointModel('temporal','bert',{'text':'./pretrainedModels-Twit15/bertTextEnc.pth','tree':'./pretrainedModels-Twit15/std_tempTreeEnc_pretrained.pth'},textparams,treeparams,X_text,y,device)\n",
    "model = model.to(device)\n",
    "modelname = 'temporalBertJoint'\n",
    "print(modelname)\n",
    "trainModel(model,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "treeparams = {\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'in_dim':8,\n",
    "    'mem_dim':100,\n",
    "    'userVects':userVects,\n",
    "    'labels':twitter15_labels,\n",
    "    'labelMap':labelMap,\n",
    "    'criterion':nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "textparams = {\n",
    "    'embedding_dim':256,\n",
    "    'hidden_dim': 50,\n",
    "    'output_dim':4,\n",
    "    'num_layers':1,\n",
    "    'bidir':True,\n",
    "    'rnnType':'gru'\n",
    "}\n",
    "\n",
    "treeTypes = ['standard']\n",
    "textTypes = ['rnn']\n",
    "pretrainTypes = [False]\n",
    "bidirTypes = [True]\n",
    "rnnTypes = ['gru']\n",
    "# attnTypes = ['dot']\n",
    "\n",
    "pretrainedFiles = {\n",
    "    'bigru':'./pretrainedModels-Twit15/bidirgru.pth',\n",
    "    'bilstm':'./pretrainedModels-Twit15/bidirlstm.pth',\n",
    "    'gru':'./pretrainedModels-Twit15/gru.pth',\n",
    "    'lstm':'./pretrainedModels-Twit15/lstm.pth',\n",
    "    'stdTreeEnc':'./pretrainedModels-Twit15/std_treeEnc_pretrained_withoutTreeLoss.pth',\n",
    "    'decayTreeEnc':'./pretrainedModels-Twit15/decay_treeEnc_pretrained_withoutTreeLoss.pth',\n",
    "}\n",
    "\n",
    "for textType in textTypes:\n",
    "    for treeType in treeTypes:\n",
    "        for pretrainType in pretrainTypes:\n",
    "            for rnnType in rnnTypes:\n",
    "                for bidirType in bidirTypes:\n",
    "                        textparams['rnnType'] = rnnType\n",
    "                        textparams['bidirType'] = bidirType\n",
    "\n",
    "                        model = jointModel(treeType,textType,pretrainType,textparams,treeparams,X_text,y,device)\n",
    "                        model = model.to(device)\n",
    "                        modelname = textType+'_'+treeType+'-tree_pretrain-'+str(pretrainType)+'_'+rnnType+'bidir-'+str(bidirType)\n",
    "                        print(modelname)\n",
    "                        trainModel(model,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "fakenews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
