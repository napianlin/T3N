{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy c-extensions failed.\n- Try uninstalling and reinstalling numpy.\n- If you have already done that, then:\n  1. Check that you expected to use Python3.7 from \"/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/bin/python\",\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy version \"1.17.4\" you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n\nNote: this error has many possible causes, so please don't comment on\nan existing issue about this - open a new one instead.\n\nOriginal error was: /home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-x86_64-linux-gnu.so: failed to map segment from shared object: Cannot allocate memory\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[1;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[0;31mImportError\u001b[0m: /home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-x86_64-linux-gnu.so: failed to map segment from shared object: Cannot allocate memory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dedecfa9702c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \"\"\" % (sys.version_info[0], sys.version_info[1], sys.executable,\n\u001b[1;32m     46\u001b[0m         __version__, exc)\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy c-extensions failed.\n- Try uninstalling and reinstalling numpy.\n- If you have already done that, then:\n  1. Check that you expected to use Python3.7 from \"/home/nikhil.pinnaparaju/anaconda3/envs/fakenews/bin/python\",\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy version \"1.17.4\" you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n\nNote: this error has many possible causes, so please don't comment on\nan existing issue about this - open a new one instead.\n\nOriginal error was: /home/nikhil.pinnaparaju/anaconda3/envs/fakenews/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-x86_64-linux-gnu.so: failed to map segment from shared object: Cannot allocate memory\n"
     ]
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../twitter15/twitter15_text_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,uid,tid,time_stamp,label):\n",
    "        self.children = {}\n",
    "        self.childrenList = []\n",
    "        self.num_children = 0\n",
    "        self.tid = tid\n",
    "        self.uid = uid\n",
    "        self.label = label\n",
    "        self.time_stamp = time_stamp\n",
    "    \n",
    "    def add_child(self,node):\n",
    "        if node.uid not in self.children:\n",
    "            self.children[node.uid] = node\n",
    "            self.num_children += 1\n",
    "        else:\n",
    "            self.children[node.uid] = node\n",
    "        self.childrenList = list(self.children.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,root):\n",
    "        self.root = root\n",
    "        self.tweet_id = root.tid\n",
    "        self.uid = root.uid\n",
    "        self.height = 0\n",
    "        self.nodes = 0\n",
    "    \n",
    "    def show(self):\n",
    "        queue = [self.root,0]\n",
    "        \n",
    "        while len(queue) != 0:\n",
    "            toprint = queue.pop(0)\n",
    "            if toprint == 0:\n",
    "                print('\\n')\n",
    "            else:\n",
    "                print(toprint.uid,end=' ')\n",
    "                queue += toprint.children.values()\n",
    "                queue.append(0)\n",
    "                \n",
    "    def insertnode(self,curnode,parent,child):\n",
    "        if curnode.uid == parent.uid:\n",
    "            curnode.add_child(child)\n",
    "            return 1\n",
    "\n",
    "        elif parent.uid in curnode.children:\n",
    "            s = self.insertnode(curnode.children[parent.uid],parent,child)\n",
    "            return 2\n",
    "        else:\n",
    "            for node in curnode.children:\n",
    "                s = self.insertnode(curnode.children[node],parent,child)\n",
    "                if s == 2:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPklFileNum(datapath,incSize,fileNum):\n",
    "    \n",
    "    with open(datapath+str(incSize)+'inc_'+str(fileNum)+'.pickle', 'rb') as handle:\n",
    "        twitTrees = pkl.load(handle)\n",
    "    return twitTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTreeFilesOfIncrement(datapath,incSize):\n",
    "    twittertrees = {}\n",
    "    \n",
    "    files = [x for x in os.listdir(t15Datapath) if str(incSize)+'inc' in x]\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        with open(datapath+file,'rb') as handle:\n",
    "            partialTrees = pkl.load(handle)\n",
    "        twittertrees.update(partialTrees)\n",
    "        \n",
    "    return twittertrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t15Datapath = '../twitter15/pickledTrees/'\n",
    "# twitter15_trees = loadPklFileNum(t15Datapath,20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter15_trees = loadTreeFilesOfIncrement(t15Datapath,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../twitter15/userdata_parser.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(userVects):\n",
    "    userVects[key] = userVects[key].float()\n",
    "\n",
    "userVects = defaultdict(lambda:torch.tensor([1.1100e+02, 1.5000e+01, 0.0000e+00, 7.9700e+02, 4.7300e+02, 0.0000e+00,\n",
    "        8.3326e+04, 1.0000e+00]),userVects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./textEncoders.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./temporal_tree_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:2'\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labelMap = {}\n",
    "labelCount = 0\n",
    "for label in list(twitter15_labels.values()):\n",
    "    if label not in labelMap:\n",
    "        labelMap[label] = labelCount\n",
    "        labelCount += 1\n",
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "X = []\n",
    "y = []\n",
    "X_text = []\n",
    "\n",
    "for tid in twitter15_trees:\n",
    "        if tid in twitter15_trees and tid in twitter15_labels:\n",
    "            X.append(tuple((twitter15_trees[tid],twitter15_text[tid])))\n",
    "            y.append(labelMap[twitter15_labels[tid]])\n",
    "            X_text.append(twitter15_text[tid])\n",
    "            \n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jointModel(nn.Module):\n",
    "    def __init__(self, treeEncoderType, textEncoderType, pretrain, textparams, treeparams, X, y, device):\n",
    "        super(jointModel, self).__init__()\n",
    "        if textEncoderType == 'rnn':\n",
    "            self.textEncoderModel = TextEncoder(textEncoderType,textparams,X,y,device)\n",
    "            textparams['hidden_dim'] = textparams['hidden_dim']*self.textEncoderModel.textEncoder.numDirs\n",
    "            \n",
    "        if textEncoderType == 'bert':\n",
    "            self.textEncoderModel = BertTextEncoder(textEncoderType,{},X,y,device)\n",
    "            textparams['hidden_dim'] = 768\n",
    "        \n",
    "        if textEncoderType == 'attn':\n",
    "            self.textEncoderModel = AttentionTextEncoder(textEncoderType,textparams,X,y,device)\n",
    "            textparams['hidden_dim'] = textparams['hidden_dim']*self.textEncoderModel.textEncoder.numDirs*self.textEncoderModel.seq_dim\n",
    "        \n",
    "        if pretrain:\n",
    "            self.textEncoderModel.trainModel()\n",
    "            self.textEncoderModel.textEncoder.load_state_dict(self.textEncoderModel.optimalParams)\n",
    "            \n",
    "        if treeEncoderType == 'standard':\n",
    "            self.treeEncoderModel = treeEncoder(treeparams['cuda'],treeparams['in_dim'],treeparams['mem_dim'],treeparams['userVects'],treeparams['labels'],treeparams['labelMap'],treeparams['criterion'],device)\n",
    "        if treeEncoderType == 'decay':\n",
    "            self.treeEncoderModel = decayTreeEncoder(treeparams['cuda'],treeparams['in_dim'],treeparams['mem_dim'],treeparams['userVects'],treeparams['labels'],treeparams['labelMap'],treeparams['criterion'],device)\n",
    "        \n",
    "        mem_dim = treeparams['mem_dim'] + textparams['hidden_dim']\n",
    "        \n",
    "        self.fc = nn.Linear(mem_dim,4)    \n",
    "            \n",
    "    def forward(self,tree,text):\n",
    "        treeVec = self.treeEncoderModel(tree)\n",
    "        treeVec = treeVec[0][1].reshape(-1)\n",
    "        \n",
    "        self.textEncoderModel.textEncoder = self.textEncoderModel.textEncoder.to('cpu')\n",
    "        textVec = self.textEncoderModel(text)\n",
    "        textVec = textVec.reshape(-1)\n",
    "#         print(treeVec.shape)\n",
    "#         print(textVec.shape)\n",
    "        combVec =  torch.cat((treeVec,textVec))\n",
    "#         combVec = textVec\n",
    "        out = self.fc(combVec)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,modelname):\n",
    "#     optimizer = torch.optim.Adagrad(model.treeEncoderModel.parameters(),0.01)\n",
    "    \n",
    "#     bertoptimizer = AdamW(model.textEncoderModel.parameters(),\n",
    "#                   lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "#                   eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "#                 )\n",
    "    \n",
    "    optimizer = torch.optim.Adagrad(model.parameters(),0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    maxAcc = 0\n",
    "    count = 0\n",
    "    netloss = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        for treeSet, text in tqdm(x_train):\n",
    "            tree = treeSet[-1]\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model(tree.root,text)\n",
    "            \n",
    "            label = Variable(torch.tensor(labelMap[treeSet[0].root.label]).reshape(-1).to(device))\n",
    "            loss = criterion(pred.reshape(1,4),label)\n",
    "#             print(loss)\n",
    "            netloss += loss\n",
    "    \n",
    "            if count % 20 == 0:\n",
    "#                 print('opt')\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        allLabels = []\n",
    "        allPreds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for valSet, text in tqdm(x_test):\n",
    "                finalTree = valSet[-1]\n",
    "\n",
    "                predicted = model(finalTree.root,text)\n",
    "                preds.append(predicted)\n",
    "        #         print(predicted)\n",
    "                predicted =  torch.softmax(predicted,0)\n",
    "                predicted = torch.max(predicted, 0)[1].cpu().numpy().tolist()\n",
    "\n",
    "                labels.append(labelMap[finalTree.root.label])\n",
    "\n",
    "                allLabels.append(labelMap[finalTree.root.label])\n",
    "                allPreds.append(predicted)\n",
    "\n",
    "            predTensor = torch.stack(preds)\n",
    "            labelTensor = torch.tensor(labels).to(device)\n",
    "\n",
    "            print(allLabels,allPreds)\n",
    "\n",
    "            loss = criterion(predTensor.reshape(-1,4), labelTensor.reshape(-1))\n",
    "\n",
    "        cr = classification_report(allLabels,allPreds,output_dict=True)\n",
    "        cr['loss'] = loss.item()\n",
    "        cr['Acc'] = accuracy_score(allLabels,allPreds,)\n",
    "\n",
    "        if cr['Acc'] > maxAcc:\n",
    "            maxAcc = cr['Acc']\n",
    "            torch.save({'state_dict': model.state_dict()}, './jointlyTrainedResults/'+modelname+'.pth')\n",
    "\n",
    "        print('loss: ',cr['loss'])\n",
    "        print(cr['Acc'])\n",
    "\n",
    "        with open('./jointlyTrainedResults/'+modelname+'json', 'a') as fp:\n",
    "            json.dump(cr, fp)\n",
    "            fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "treeparams = {\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'in_dim':8,\n",
    "    'mem_dim':100,\n",
    "    'userVects':userVects,\n",
    "    'labels':twitter15_labels,\n",
    "    'labelMap':labelMap,\n",
    "    'criterion':nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "textparams = {\n",
    "    'embedding_dim':256,\n",
    "    'hidden_dim': 50,\n",
    "    'output_dim':4,\n",
    "    'num_layers':1,\n",
    "    'bidir':True,\n",
    "    'rnnType':'gru'\n",
    "}\n",
    "\n",
    "treeTypes = ['standard','decay']\n",
    "textTypes = ['bert']\n",
    "pretrainTypes = [True,False]\n",
    "\n",
    "treeTypes = ['standard','decay']\n",
    "textTypes = ['bert']\n",
    "pretrainTypes = [True]\n",
    "\n",
    "for textType in textTypes:\n",
    "    for treeType in treeTypes:\n",
    "        for pretrainType in pretrainTypes:\n",
    "            model = jointModel(treeType,textType,pretrainType,textparams,treeparams,X_text,y,device)\n",
    "            model = model.to(device)\n",
    "            modelname = textType+'_'+treeType+'-tree_pretrain-'+str(pretrainType)\n",
    "            print(modelname)\n",
    "            trainModel(model,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeparams = {\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'in_dim':8,\n",
    "    'mem_dim':100,\n",
    "    'userVects':userVects,\n",
    "    'labels':twitter15_labels,\n",
    "    'labelMap':labelMap,\n",
    "    'criterion':nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "textparams = {\n",
    "    'embedding_dim':256,\n",
    "    'hidden_dim': 50,\n",
    "    'output_dim':4,\n",
    "    'num_layers':1,\n",
    "    'bidir':True,\n",
    "    'rnnType':'gru'\n",
    "}\n",
    "\n",
    "treeTypes = ['standard']\n",
    "textTypes = ['rnn']\n",
    "pretrainTypes = [True,False]\n",
    "bidirTypes = [True,False]\n",
    "rnnTypes = ['lstm','gru']\n",
    "\n",
    "for textType in textTypes:\n",
    "    for treeType in treeTypes:\n",
    "        for pretrainType in pretrainTypes:\n",
    "            for rnnType in rnnTypes:\n",
    "                for bidirType in bidirTypes:\n",
    "                    textparams['rnnType'] = rnnType\n",
    "                    textparams['bidirType'] = bidirType\n",
    "                    \n",
    "                    model = jointModel(treeType,textType,pretrainType,textparams,treeparams,X_text,y,device)\n",
    "                    model = model.to(device)\n",
    "                    modelname = textType+'_'+treeType+'-tree_pretrain-'+str(pretrainType)+'_'+rnnType+'bidir-'+str(bidirType)\n",
    "                    print(modelname)\n",
    "                    trainModel(model,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "fakenews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
